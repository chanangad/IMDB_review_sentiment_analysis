{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/pickled-glove840b300d-for-10sec-loading/glove.840B.300d.pkl\n",
      "/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive examples 25000\n",
      "Negative examples 25000\n"
     ]
    }
   ],
   "source": [
    "print(\"Positive examples {0:.0f}\".format(data.groupby('sentiment')['sentiment'].count().positive))\n",
    "print(\"Negative examples {0:.0f}\".format(data.groupby('sentiment')['sentiment'].count().negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 635766),\n",
       " ('a', 315257),\n",
       " ('and', 313549),\n",
       " ('of', 286598),\n",
       " ('to', 264402),\n",
       " ('is', 204825),\n",
       " ('in', 179158),\n",
       " ('i', 132384),\n",
       " ('this', 131309),\n",
       " ('that', 130096),\n",
       " ('it', 129013),\n",
       " ('/><br', 100979),\n",
       " ('was', 93232),\n",
       " ('as', 87679),\n",
       " ('with', 84455),\n",
       " ('for', 84197),\n",
       " ('but', 77832),\n",
       " ('on', 62807),\n",
       " ('movie', 61431),\n",
       " ('are', 56996),\n",
       " ('his', 56863),\n",
       " ('not', 56568),\n",
       " ('you', 55395),\n",
       " ('film', 55043),\n",
       " ('have', 54383),\n",
       " ('he', 51050),\n",
       " ('be', 50891),\n",
       " ('at', 45133),\n",
       " ('one', 44596),\n",
       " ('by', 43303),\n",
       " ('an', 42098),\n",
       " ('they', 40820),\n",
       " ('from', 39203),\n",
       " ('all', 38462),\n",
       " ('who', 38277),\n",
       " ('like', 37159),\n",
       " ('so', 35840),\n",
       " ('just', 34058),\n",
       " ('or', 33286),\n",
       " ('has', 32596),\n",
       " ('about', 32374),\n",
       " ('her', 31240),\n",
       " (\"it's\", 30762),\n",
       " ('some', 30032),\n",
       " ('if', 30015),\n",
       " ('out', 28960),\n",
       " ('what', 27452),\n",
       " ('very', 26820),\n",
       " ('when', 26286),\n",
       " ('more', 25851),\n",
       " ('there', 25602),\n",
       " ('would', 23792),\n",
       " ('even', 23581),\n",
       " ('she', 23415),\n",
       " ('good', 23403),\n",
       " ('my', 23078),\n",
       " ('their', 22603),\n",
       " ('only', 22562),\n",
       " ('no', 22293),\n",
       " ('really', 21785),\n",
       " ('had', 21575),\n",
       " ('up', 21404),\n",
       " ('can', 21298),\n",
       " ('which', 21151),\n",
       " ('see', 20894),\n",
       " ('were', 20705),\n",
       " ('than', 19106),\n",
       " ('we', 18218),\n",
       " ('-', 18183),\n",
       " ('been', 17938),\n",
       " ('get', 17683),\n",
       " ('into', 17585),\n",
       " ('will', 17560),\n",
       " ('much', 17252),\n",
       " ('because', 17113),\n",
       " ('story', 16790),\n",
       " ('most', 16680),\n",
       " ('how', 16603),\n",
       " ('other', 16360),\n",
       " ('also', 15738),\n",
       " ('do', 15727),\n",
       " ('time', 15622),\n",
       " (\"don't\", 15610),\n",
       " ('its', 15602),\n",
       " ('me', 15472),\n",
       " ('great', 15388),\n",
       " ('first', 15120),\n",
       " ('make', 15020),\n",
       " ('people', 14997),\n",
       " ('could', 14919),\n",
       " ('/>the', 14769),\n",
       " ('any', 14707),\n",
       " ('then', 13756),\n",
       " ('after', 13545),\n",
       " ('made', 13545),\n",
       " ('bad', 13469),\n",
       " ('think', 13288),\n",
       " ('many', 12823),\n",
       " ('never', 12593),\n",
       " ('being', 12589)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "a = ''.join(data['review'].values)\n",
    "a= a.lower()\n",
    "a = list(a.split())\n",
    "\n",
    "Counter(list(a)).most_common(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stop Words**\n",
    "\n",
    "For the purpose of sentiment analysis we cannot use the nltk package's predefined stopword list as it has many words like 'not', 'did', etc. which are important for the purpose of analysing the sentiment\n",
    "\n",
    "Hence I've made a custom list of stop_words which do not have any contribution to the sentiment of a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(['the','a','and','of','to','in','this','that','on','an','that'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-Processing**\n",
    "\n",
    "For pre-process, we firstly tokenize the sentence and then apply a lemmatizer followed by removal of the stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "#from nltk.corpus import stopwords\n",
    "#eng_stop_words = set(stopwords.words('english'))\n",
    "wnl = WordNetLemmatizer()\n",
    "def pre_process(text):\n",
    "        text = [token for token in word_tokenize(text)]\n",
    "        text = [wnl.lemmatize(token) for token in text]\n",
    "        text = [wnl.lemmatize(token,'v') for token in text]\n",
    "        text = [token for token in text if not token in stop_words]\n",
    "        text = \" \".join(text)\n",
    "        return text\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>One other reviewer ha mention after watch just...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>A wonderful little production . &lt; br / &gt; &lt; br ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>I think wa wonderful way spend time too hot su...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Basically there 's family where little boy ( J...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Petter Mattei 's `` Love Time Money '' be visu...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One other reviewer ha mention after watch just...  positive\n",
       "1  A wonderful little production . < br / > < br ...  positive\n",
       "2  I think wa wonderful way spend time too hot su...  positive\n",
       "3  Basically there 's family where little boy ( J...  negative\n",
       "4  Petter Mattei 's `` Love Time Money '' be visu...  positive"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['review'] = data.review.apply(pre_process)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = pd.read_pickle('/kaggle/input/pickled-glove840b300d-for-10sec-loading/glove.840B.300d.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average tokens per example is 232\n",
      "Max tokens per example is 2393\n",
      "Min tokens per example is 6\n",
      "Median tokens per example is 174\n"
     ]
    }
   ],
   "source": [
    "print(\"Average tokens per example is {0:.0f}\".format(np.mean(data['review'].apply(lambda x: len(x.split())))))\n",
    "print(\"Max tokens per example is {0:.0f}\".format(np.max(data['review'].apply(lambda x: len(x.split())))))\n",
    "print(\"Min tokens per example is {0:.0f}\".format(np.min(data['review'].apply(lambda x: len(x.split())))))\n",
    "print(\"Median tokens per example is {0:.0f}\".format(np.median(data['review'].apply(lambda x: len(x.split())))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "tok = Tokenizer(lower = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text = list((''.join(data['review'].values).split()))\n",
    "tok.fit_on_texts(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100700"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tok.word_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tok = tok.texts_to_sequences(data['review'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "X_train = pad_sequences(train_tok, maxlen = 230)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y_enc = encoder.fit_transform(data['sentiment'].values.reshape(-1, 1))\n",
    "y_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 300\n",
    "NB_WORDS = len(tok.word_index)  #here we consider only the top 30000 most frequently occuring words \n",
    "emb_matrix = np.zeros((NB_WORDS+1, dim))\n",
    "for w, i in tok.word_index.items():\n",
    "    if i < NB_WORDS:\n",
    "        vect = embed.get(w)\n",
    "        if vect is not None:\n",
    "            emb_matrix[i] = vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 230, 300)          30210300  \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128)               186880    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 30,397,438\n",
      "Trainable params: 187,138\n",
      "Non-trainable params: 30,210,300\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "45000/45000 [==============================] - 146s 3ms/step - loss: 0.4634 - accuracy: 0.7778 - val_loss: 0.3429 - val_accuracy: 0.8526\n",
      "Epoch 2/10\n",
      "45000/45000 [==============================] - 144s 3ms/step - loss: 0.3509 - accuracy: 0.8486 - val_loss: 0.2951 - val_accuracy: 0.8792\n",
      "Epoch 3/10\n",
      "45000/45000 [==============================] - 146s 3ms/step - loss: 0.2998 - accuracy: 0.8722 - val_loss: 0.2795 - val_accuracy: 0.8814\n",
      "Epoch 4/10\n",
      "45000/45000 [==============================] - 144s 3ms/step - loss: 0.2707 - accuracy: 0.8863 - val_loss: 0.2613 - val_accuracy: 0.8904\n",
      "Epoch 5/10\n",
      "45000/45000 [==============================] - 145s 3ms/step - loss: 0.2521 - accuracy: 0.8962 - val_loss: 0.2526 - val_accuracy: 0.8936\n",
      "Epoch 6/10\n",
      "45000/45000 [==============================] - 142s 3ms/step - loss: 0.2292 - accuracy: 0.9060 - val_loss: 0.2419 - val_accuracy: 0.8992\n",
      "Epoch 7/10\n",
      "45000/45000 [==============================] - 142s 3ms/step - loss: 0.2144 - accuracy: 0.9125 - val_loss: 0.2428 - val_accuracy: 0.9026\n",
      "Epoch 8/10\n",
      "45000/45000 [==============================] - 144s 3ms/step - loss: 0.1988 - accuracy: 0.9205 - val_loss: 0.2422 - val_accuracy: 0.8984\n",
      "Epoch 9/10\n",
      "45000/45000 [==============================] - 143s 3ms/step - loss: 0.1836 - accuracy: 0.9267 - val_loss: 0.2416 - val_accuracy: 0.9030\n",
      "Epoch 10/10\n",
      "45000/45000 [==============================] - 144s 3ms/step - loss: 0.1687 - accuracy: 0.9337 - val_loss: 0.2505 - val_accuracy: 0.8998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f65d00cc5f8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A simple LSTM \n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(NB_WORDS+1, dim,weights=[emb_matrix], input_length=230,trainable=False))\n",
    "model.add(Bidirectional(LSTM(64,dropout=0.2)))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_enc, epochs=10, batch_size=128,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(model,open('LSTM_Model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rev = \"I didn't like the movie honestly. The storyline was way too mainstream and the ending was quite expected. One time watch!\"\n",
    "rev = pre_process(rev)\n",
    "print(rev)\n",
    "rev_tok = tok.texts_to_sequences(rev)\n",
    "rev_mod = pad_sequences(rev_tok, maxlen = 130)\n",
    "model.predict(rev_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rev_tok = tok.texts_to_sequences([\"I absolutely hated movie honestly worst The storyline wa way mainstream end wa quite expect One time watch\"])\n",
    "rev_mod = pad_sequences(rev_tok, maxlen = 130)\n",
    "rev_mod"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
